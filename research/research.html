<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Research & Publications</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="stylesheet.css">

    <style>
      /* Center the table and set a maximum width */
      body {
        font-family: Arial, sans-serif;
        background-color: #f4f4f4;
      }

      #research {
        width: 100%;
        max-width: 900px;  /* Max width to prevent stretching */
        margin: 0 auto;  /* Center the table */
        padding: 20px;
        background-color: #fff;
        border-radius: 8px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
      }

      h2 {
        text-align: center;
        color: #333;
      }

      td {
        padding: 10px;
      }

      p, em {
        color: #555;
      }

      /* Style for links */
      a {
        color: #0066cc;
        text-decoration: none;
      }

      a:hover {
        text-decoration: underline;
      }

      /* Style for media elements */
      iframe, img {
        border: none;
        border-radius: 8px;
      }

      /* Smaller screens adjustments */
      @media (max-width: 600px) {
        #research {
          padding: 10px;
        }

        iframe, img {
          width: 100%;
          height: auto;
        }
      }
    </style>
  </head>
  <body>

    <!-- Research & Publications Section -->
    <table id="research">
      <tr>
        <td colspan="2" style="vertical-align:middle">
          <h2>Research & Publications</h2>
        </td>
      </tr>

      <!-- Legged Robot Navigation Project (Research 1) -->
      <tr>
        <td style="vertical-align:top">
          <a href="https://drive.google.com/file/d/1VOAhbj0JYWm-aivxUDTKNbys2pnibXPD/view?usp=sharing">
            <span class="papertitle">Legged Robot Navigation in Uncertain Terrains using Deep Reinforcement Learning.</span>
          </a>
          <br>
          <em>Georgia Institute of Technology | Research Project</em>
          <br>
          <p>Worked on this legged robot navigation project with Dr. Sehoon Ha at Georgia Tech. Developed and vectorized the robot environment in the RaiSim simulator using C++ and Python bindings. Achieved over 95% success rate for the baseline point-to-goal navigation policy on a flat plane using PPO. Created different terrains for uncertain terrains traversal, with future plans for training an imitation learning policy.</p>
        </td>
      </tr>

      <!-- Report and Videos for the Legged Robot Navigation Project -->
      <tr>
        <td colspan="2" style="vertical-align:middle">
          <table style="width:100%;text-align:center;">
            <tr>
              <!-- Inline PDF Viewer for Report -->
              <td style="padding:10px">
                <iframe src="https://drive.google.com/file/d/1VOAhbj0JYWm-aivxUDTKNbys2pnibXPD/preview" style="width:300px;height:200px;" loading="lazy"></iframe>
                <p style="font-size:small">View Full Project Report</p>
              </td>
              
              <!-- Embedded Video 1 from Google Drive -->
              <td style="padding:10px">
                <iframe src="https://drive.google.com/file/d/1V7_6QbQywA20UvEP3XbFfvrYVioojA_F/preview" width="300" height="200" allow="autoplay" loading="lazy"></iframe>
                <p style="font-size:small">Watch Video 01</p>
              </td>
              
              <!-- Embedded Video 2 from Google Drive -->
              <td style="padding:10px">
                <iframe src="https://drive.google.com/file/d/1V88QNcGsLN44wQ76EdNuBSbziz7VqR5I/preview" width="300" height="200" allow="autoplay" loading="lazy"></iframe>
                <p style="font-size:small">Watch Video 02</p>
              </td>
            </tr>
          </table>
        </td>
      </tr>

      <!-- AI Model Project (Research 2) -->
      <tr>
        <td style="vertical-align:top">
          <a href="https://europepmc.org/article/med/36705317">
            <span class="papertitle">An Artificial Intelligence Model for Instance Segmentation and Tooth Numbering on Orthopantomograms.</span>
          </a>
          <br>
          <em>Niha Adnan, Waleed Bin Khalid, Fahad Umer | International Journal of Computerized Dentistry 2023</em>
          <br>
          <p>Developed a deep-learning pipeline for teeth segmentation using U-NET and FRCNN. The Orthopantomograms dataset was self-annotated & processed for the project using PIL, numpy, JSON & OpenCV.</p>
        </td>
      </tr>

      <!-- Image and Publication Link for the AI Model Project -->
      <tr>
        <td colspan="2" style="vertical-align:middle">
          <table style="width:100%;text-align:center;">
            <tr>
              <!-- Image 01 for the Research -->
              <td style="padding:10px">
                <a href="images/5 - mask.png" target="_blank">
                  <img src="images/5 - mask.png" alt="AI Model for Instance Segmentation" style="width:300px;height:200px;" loading="lazy">
                </a>
                <p style="font-size:small">Visualization of Instance Segmentation and Tooth Numbering</p>
              </td>
              
              <!-- AIpaperImage as Link to the Published Article -->
              <td style="padding:10px">
                <a href="https://europepmc.org/article/med/36705317" target="_blank">
                  <img src="images/AIpaperImage.png" alt="Link to Article" style="width:300px;height:200px;" loading="lazy">
                </a>
                <p style="font-size:small">View Full Publication</p>
              </td>
            </tr>
          </table>
        </td>
      </tr>

      <!-- Contactless Vitals Measurement Robot (Research 3) -->
      <tr>
        <td style="vertical-align:top">
          <a href="https://ieeexplore.ieee.org/document/9738523">
            <span class="papertitle">Contactless Vitals Measurement Robot.</span>
          </a>
          <br>
          <em>Waleed Bin Khalid, Amna Anwar, Owais Talaat Waheed | International Conference on Automation, Robotics, and Applications 2022</em>
          <br>
          <p>Researched the use of Image processing for photoplethysmography to develop a non-contact vitals measurement robot. Presented the work at ICARA 2022 and received the Best Capstone Project award.</p>
        </td>
      </tr>

      <!-- Thesis, Video, and Publication Link for the Contactless Vitals Measurement Project -->
      <tr>
        <td colspan="2" style="vertical-align:middle">
          <table style="width:100%;text-align:center;">
            <tr>
              <!-- Inline PDF Viewer for Thesis -->
              <td style="padding:10px">
                <iframe src="https://drive.google.com/file/d/1dmpo7BZbzWkDmhA3sYa2WLOv3P7I_K-t/preview" style="width:300px;height:200px;" loading="lazy"></iframe>
                <p style="font-size:small">View Full Thesis</p>
              </td>
              
              <!-- Display for IEEE Publication Link -->
              <td style="padding:10px">
                <a href="https://ieeexplore.ieee.org/document/9738523" target="_blank">
                  <img src="images/ieeePageDisplay.png" alt="IEEE Publication" style="width:300px;height:200px;" loading="lazy">
                </a>
                <p style="font-size:small">View IEEE Publication</p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>

  </body>
</html>
